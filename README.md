# general informations
There are two implementations:
* one in Spring Boot + REST with synchronous communication,
* one in Quarkus + REST with both synchronous and non-blocking asynchronous communication

My implementation is the first one: Spring Boot version, other one is kind of "experimental", more info in decisions log at the bottom of this document

# build
Spring Boot app has obvious/common way of building and running for maven projects, "mvn clean install" to build, "java -jar ..." to run, the app is running on default port 8080
Quarkus app has own README.md with more details about building it, as it is not so common I left autogenerated, more "verbose" explanation how to use it, port also default 8080

# API 

**path: /transform**

method: POST

input data: body should be a string representation of nested arrays, example: 

```[[10,[[20, [30]]],[40]]]```

output data: String representation of flat structure and max deep of original data, example 

```[10,20,30,40], deep: 2```

communication type: sync

*this endpoint exists in both: Spring Boot and Quarkus apps*

--

**path: /async/transform**

method: POST

input data: body should be a string representation of nested arrays, example: 

```[[10,[[20, [30]]],[40]]]```

output data: String representation of flat structure and max deep of original data, example 

```[10,20,30,40], deep: 2```

communication type: async

*this endpoint exists only in Quarkus app*

--

# Decisions Log

1. How to solve problem? It was quite obvious that using well known algorithm is a good idea, perfect fit to this situation is "Depth-first search" (short name "DFS") so I decided to use it rather than any other "custom" algorithms to make it easy to understand and have proven efficiency.
1. Data structure. DFS works with trees and graphs in general so natural choice was to use some tree representation, also well known easy to understand for others
1. Input and Output format. I just took format from examples to make sure it will fit to "others systems", it was just in requirements, but in general it is not the best format that I would use, I would try to force in the project using standard JSON format for output, input is proper JSON already.
1. Parse input to some tree. Here was the fist small problem, I couldn't find any existing lib that was able out of the box to transform from nested arrays to tree, 15 minutes of searching and I decided to implement own parser for that
1. Service class with business logic implemented, basic unit tests implemented and passing, so next step was to wrap it to some API and frameworks, I decided to use Spring Boot, REST, sync communication - as there was no specific requirements, it is the easiest way to implement API, easiest to understand for others developers or API clients, easiest to implement on client side and remember the rule "KISS", anyway change from sync to async in Spring is easy, as well as changing technology if you have proper business logic separation
1. Code organisation, packages, I decided to make it "package per feature" not "package per class role" because it is much easier to decouple later when app is getting big, so we have only one feature, anything connected to this feature is in one package, another feature would have own set of class in own java package
1. More tests. At this point I decided to check how fast is my solution, is it good for sync or definetely it should be non-blocking async endpoint?, is the algorithm fast enough?, how mych time it takes to parse to tree and how much it takes to go through it? finally if it all make sense with more complicated data or should I improve anything? So I wrote test data generator in Test class that is able to generate any size proper input data and I wrote two tests, one with 1000 elements and one with 1 000 000 elements, processing time is IMO good, as I don't have any requirements about timing and input data size I decided it is reasonable good (few ms of processing for 1k elements, abound 300ms for 1 mln elements), no need to waste time for better data structure, algorithm or parallel processing.
1. Some experimets, I invested some time to check out Quarkus, it was my first implementation ever in this framework, I already had nicely separated business logic and API wrapper so having the same solution in, as they say "supersonic fast", Quarkus took me one hour and it works very well, after I added async endpoint ad it was extremely easy and fast to develop, anyway for big modules I would avoid Quarkus, for small things it may be nice to use on production :) 
1. If I would have more time I would write some good error handler, also I would write some input validation, some docker image build scripts, maybe some deployment scripts etc, but I have some more recruitment processes in progress and I am writing some more sample codes for others - effectively I had no time to use full week for this implementation (I mention about it because transparency, trust and being honest is a key for successful cooperation, so le's start it from day zero :) )




















